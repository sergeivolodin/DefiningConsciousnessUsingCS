\documentclass[a4paper, 12pt]{article}
\usepackage[margin=2.5cm]{geometry}
\renewcommand{\baselinestretch}{1.5}
\usepackage{hyperref}
\usepackage{graphicx}
%opening
\title{Philosophy of Life Sciences.\\ Definition of consciousness (Computer Science part)}
\author{Sergei Volodin, EPFL MSc student}
\date{}

\begin{document}

\maketitle

\begin{abstract}
In this essay, a question of whether or not artificial consciousness is possible is addressed.
Despite enormous efforts, the definition seemed to slip through our fingers, and there is no unified theory still.
On the other hand, during the past fifty years, a number of significant breakthroughs in Artificial Intelligence allowed to answer a few questions about what consciousness {\em is not}.
Another part of these breakthroughs is the Integrated information theory, which gives a set of necessary properties required for a physical system to be conscious.
\end{abstract}

%\tableofcontents

\section{Introduction}
In this (part of an) essay the existence of an artificial consciousness is being proven. The main problem of answering to this question is that there is no consensus on what a natural consciousness is. Various definitions of consciousness based on recent breakthroughs in Artificial Intelligence are used.

Consciousness studies are divided into two directions. The first one address the {\em easy problem} \cite{chalmers}, which is tightly connected to cognition and behavior. This part is aimed at explaining such phenomena as information integration, attention, control of behavior, ability to react to stimuli and others. The other one is aimed at explaining the {\em hard problem}, which is the {\em experience} of the world around us and of the inner mental states.

Philosophical zombie is a concept which possesses all of the {\em easy} qualities of consciousness, but lacks the {\em hard} consciousness (experience). In this essay, the {\em hard} kind of Artificial Consciousness is being addressed.

There are different views on {\em hard} and {\em easy} problems. The first view (functionalism) claims that the hard problem simply does not exist. It means that the experience is not a property of its own and it is simply a by-product of cognition. Thus, any system which is able to perform easy problems, possesses hard consciousness, and philosophical zombies are not possible. Many arguments exist which try to undermine such a view. Most notable are the Chinese room thought experiment and Chinese brain thought experiment.

Recent breakthroughs in Neuroscience demand that the problem of HAC being answered. For example, in next few years it might become technically possible \cite{bluebrain} to create thin slices of a human brain and for each slice detect the neuron types and the connections between types. Since the dynamics of individual neurons is known \cite{hh}, it would be possible to simulate the whole human brain. The question arises: is this artificial system possess HAC? Clearly, such a system would plausibly solve all of the easy problems, since it is computationally equivalent. But the existence of experience is put under question.

Moreover, recent advances in the subfield of AI, namely, Reinforcement Learning \cite{rl}, start posing questions such as ,,Are present-day RL agents conscious, and to what degree?'' \cite{tomasik}.

The most famous present-day intelligence test, the Turing test, addresses only the behavioral issue. It means that a philosophical zombie can pass this test.

The three problems posed above beg for a new definition of consciousness and a new test for it, which would require more than the analysis of behavior, namely, the analysis of the inner workings of the model. Since the degree of consciousness of a particular system should be a well-defined property, the definition in question should be constructive enough to be applied to any physical system with a definite outcome, possibly consisting of a set of sufficient and necessary conditions.

One of such theories, which give a set of necessary conditions, is the Integrated Information Theory of Consciousness \cite{iit}. This theory has very promising results. It starts with fundamental properties of consciousness, which are experienced by people. Then, these properties are formulated as axioms of the theory. Then conditions for a physical system which would be able to implement such properties are analyzed. The theory has promising results, namely, some simple systems do fit the definition, when more complex systems don't. The criteria is tightly linked with the Integrated Information.

%What am I looking for?
%0. Some structure (theory) in theory of learning/information theory need to learn/compute = consciousness?
%1. Definition which explains which parts are required for a system to be conscious
%2. Explain why hard problem (experience) exist
%3. What about information processing?
%4. What about action selection?
%5. What about learning?
%6. What about language?

%All of the human qualities can be imitated. Does it make the creature intelligent? Is sort of infinity required?

%How can I choose something with consciousness without using words? How does it encode choice indices? What is the maximal \#choices?

\section{Argument}
\section{Conclusion}
\section{Raw ideas for thesis}
\begin{enumerate}
	\item Can HAC exist?
	\item Are p-zombies possible?
	\item Can have qualia of 1 bit?
	\item Turing test problems: only behavior, allows for a philosophical zombie. Depends on the intelligence of 'human' part
\end{enumerate}
\section{Plan}
\begin{enumerate}
	\item Thesis: Hard Artificial Consciousness (HAC) is possible
	\item Definitions: HPC, AC
	\item Importance: AI safety, superintelligence, ethics
	\item Argument: IIT. Support for argument
	\item Analysis of definitions which do not support this claim.
	\item Problems with existing definitions. Problems with artificial systems.
\end{enumerate}

\href{https://docs.google.com/document/d/1kh4wC9YHNJEcCBxE1eaymw9PPa1VdCW25BH0GEIQgj4/edit#heading=h.ptmcnj925n6h}{Annotated bibliography on Drive}
\begin{thebibliography}{20}
\bibitem{chalmers} Facing Up to the Problem of Consciousness, David Chalmers, 1995
\bibitem{bluebrain} The Blue Brain Project: \href{https://bluebrain.epfl.ch/}{bluebrain.epfl.ch}
\bibitem{hh} Neuronal Dynamics of Cognition. Hodgkin-Huxley Model. Wulfram Gerstner et al, 2014
\bibitem{tomasik} Do Artificial Reinforcement-Learning Agents Matter Morally, Tomasik, 2014
\bibitem{rl} Reinforcement Learning: An Introduction. Sutton, Barto, 1998
\bibitem{iit} An information integration theory of consciousness, Tononi, 2004
\end{thebibliography}
\end{document}
